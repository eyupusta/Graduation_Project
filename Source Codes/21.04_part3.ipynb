{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm \n",
    "from sklearn.utils import shuffle \n",
    "from collections import Counter \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.models import Sequential, Model\n",
    "from keras import optimizers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arff(filename):\n",
    "\ttry:\n",
    "\t\tfile = open(filename)\n",
    "\texcept:\n",
    "\t\tprint('file could not found or opened, try with file location')\n",
    "\tcolumns = []\n",
    "\tdata = []\n",
    "\n",
    "\tfor line in file:\n",
    "\t\tif line.startswith('@attribute'):\n",
    "\t\t\tline = line.strip()\n",
    "\t\t\ttemp = line.split()\n",
    "\t\t\tcolumns.append(temp[1])\n",
    "\t\telif line.startswith('@') or line.startswith('\\n'):\n",
    "\t\t\tcontinue\n",
    "\t\telse:\n",
    "\t\t\tline = line.strip()\n",
    "\t\t\ttemp = line.split(',')\n",
    "\t\t\tdata.append(temp)\n",
    "\n",
    "\treturn data,columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, columns = parse_arff('./Training Dataset.arff')\n",
    "df = pd.DataFrame(data, columns = columns, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df[df.columns[:-1]],df[df.columns[-1]], test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train).astype(np.int8)\n",
    "y_train = np.array(y_train).astype(np.int8)\n",
    "x_test = np.array(x_test).astype(np.int8)\n",
    "y_test = np.array(y_test).astype(np.int8)\n",
    "y_train = np.where(y_train == -1, 0, y_train)\n",
    "y_test = np.where(y_test == -1, 0, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.Huber(delta=1.0)\n",
    "activation = ['softplus', 'softsign', 'selu', 'elu', 'exponential', 'tanh', 'sigmoid', 'relu']\n",
    "optimizers = ['sgd', 'rmsprop', 'adam', 'adadelta', 'adagrad', 'adamax', 'nadam', 'ftrl']\n",
    "binary_loss = ['binary_crossentropy', 'hinge', 'squared_hinge', loss_fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train.reshape((x_train.shape[0], 2, 5, 3))\n",
    "xt = x_test.reshape((x_test.shape[0], 2, 5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(64,(1,1), activation='relu',input_shape=(2,5,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(128,(1,1),activation='relu'))\n",
    "model.add(keras.layers.Conv2D(128,(1,1),activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(1,activation='softplus'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softplus_train = []\n",
    "softplus_val = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary_loss:\n",
    "        model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "        modelhistory = model.fit(x, y_train, epochs = 20, validation_data=(xt, y_test))\n",
    "        softplus_train.append(modelhistory.history['accuracy'])\n",
    "        softplus_val.append(modelhistory.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(64,(1,1), activation='relu',input_shape=(2,5,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(128,(1,1),activation='relu'))\n",
    "model.add(keras.layers.Conv2D(128,(1,1),activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(1,activation='softsign'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softsign_train = []\n",
    "softsign_val = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary_loss:\n",
    "        model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "        modelhistory = model.fit(x, y_train, epochs = 20, validation_data=(xt, y_test))\n",
    "        softsign_train.append(modelhistory.history['accuracy'])\n",
    "        softsign_val.append(modelhistory.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(64,(1,1), activation='relu',input_shape=(2,5,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(128,(1,1),activation='relu'))\n",
    "model.add(keras.layers.Conv2D(128,(1,1),activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(1,activation='selu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selu_train = []\n",
    "selu_val = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary_loss:\n",
    "        model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "        modelhistory = model.fit(x, y_train, epochs = 20, validation_data=(xt, y_test))\n",
    "        selu_train.append(modelhistory.history['accuracy'])\n",
    "        selu_val.append(modelhistory.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(64,(1,1), activation='relu',input_shape=(2,5,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(128,(1,1),activation='relu'))\n",
    "model.add(keras.layers.Conv2D(128,(1,1),activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(1,activation='elu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elu_train = []\n",
    "elu_val = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary_loss:\n",
    "        model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "        modelhistory = model.fit(x, y_train, epochs = 20, validation_data=(xt, y_test))\n",
    "        elu_train.append(modelhistory.history['accuracy'])\n",
    "        elu_val.append(modelhistory.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(64,(1,1), activation='relu',input_shape=(2,5,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(128,(1,1),activation='relu'))\n",
    "model.add(keras.layers.Conv2D(128,(1,1),activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(1,activation='exponential'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_train = []\n",
    "exp_val = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary_loss:\n",
    "        model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "        modelhistory = model.fit(x, y_train, epochs = 20, validation_data=(xt, y_test))\n",
    "        exp_train.append(modelhistory.history['accuracy'])\n",
    "        exp_val.append(modelhistory.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(64,(1,1), activation='relu',input_shape=(2,5,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(128,(1,1),activation='relu'))\n",
    "model.add(keras.layers.Conv2D(128,(1,1),activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(1,activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tanh_train = []\n",
    "tanh_val = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary_loss:\n",
    "        model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "        modelhistory = model.fit(x, y_train, epochs = 20, validation_data=(xt, y_test))\n",
    "        tanh_train.append(modelhistory.history['accuracy'])\n",
    "        tanh_val.append(modelhistory.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(64,(1,1), activation='relu',input_shape=(2,5,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(128,(1,1),activation='relu'))\n",
    "model.add(keras.layers.Conv2D(128,(1,1),activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_train = []\n",
    "sigmoid_val = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary_loss:\n",
    "        model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "        modelhistory = model.fit(x, y_train, epochs = 20, validation_data=(xt, y_test))\n",
    "        sigmoid_train.append(modelhistory.history['accuracy'])\n",
    "        sigmoid_val.append(modelhistory.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(64,(1,1), activation='relu',input_shape=(2,5,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(128,(1,1),activation='relu'))\n",
    "model.add(keras.layers.Conv2D(128,(1,1),activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(1,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_train = []\n",
    "relu_val = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary_loss:\n",
    "        model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "        modelhistory = model.fit(x, y_train, epochs = 20, validation_data=(xt, y_test))\n",
    "        relu_train.append(modelhistory.history['accuracy'])\n",
    "        relu_val.append(modelhistory.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softplus_train = []\n",
    "softplus_val = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary_loss:\n",
    "        model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "        modelhistory = model.fit(x, y_train, epochs = 20, validation_data=(xt, y_test))\n",
    "        softplus_train.append(modelhistory.history['accuracy'])\n",
    "        softplus_val.append(modelhistory.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softlus = np.array(softlus_train)\n",
    "softlusv = np.array(softlus_val)\n",
    "softsign = np.array(softsign_train)\n",
    "softsignv = np.array(softsign_val)\n",
    "selu = np.array(selu_train)\n",
    "seluv = np.array(selu_val)\n",
    "elu = np.array(elu_train)\n",
    "eluv = np.array(elu_val)\n",
    "exp = np.array(exp_train)\n",
    "expv = np.array(exp_val)\n",
    "tanh = np.array(tanh_train)\n",
    "tanhv = np.array(tanh_val)\n",
    "sigmoid = np.array(sigmoid_train)\n",
    "sigmoidv = np.array(sigmoid_val)\n",
    "relu = np.array(relu_train)\n",
    "reluv = np.array(relu_val)\n",
    "binary = ['b_cros', 'hinge', 'sq_hinge', 'huber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_comb = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary:\n",
    "        sigmoid_comb.append(opt + ' ' + loss)\n",
    "\n",
    "best_accuracy_train = []\n",
    "last_accuracy_train = []\n",
    "best_accuracy_val = []\n",
    "last_accuracy_val = []\n",
    "\n",
    "for i in range(sigmoid.shape[0]):\n",
    "  best_accuracy_train.append(np.max(sigmoid[i]))\n",
    "  last_accuracy_train.append(sigmoid[i,-1])\n",
    "  best_accuracy_val.append(np.max(sigmoidv[i]))\n",
    "  last_accuracy_val.append(sigmoidv[i,-1])\n",
    "\n",
    "best_accuracy_train = np.array(best_accuracy_train)\n",
    "last_accuracy_train = np.array(last_accuracy_train)\n",
    "best_accuracy_val = np.array(best_accuracy_val)\n",
    "last_accuracy_val = np.array(last_accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(115, 15))\n",
    "plt.subplot(1,2,1) \n",
    "plt.plot(sigmoid_comb, best_accuracy_train, 'r', label='train acc')\n",
    "plt.plot(sigmoid_comb, last_accuracy_train, 'o', label='last t acc')\n",
    "plt.plot(sigmoid_comb, best_accuracy_val, 'b', label='val acc')\n",
    "plt.plot(sigmoid_comb, last_accuracy_val, '*', label='last v acc')\n",
    "plt.title('SIGMOID ACTIVATION')\n",
    "plt.xlabel('combination')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tanh_comb = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary:\n",
    "        tanh_comb.append(opt + ' ' + loss)\n",
    "\n",
    "best_accuracy_train = []\n",
    "last_accuracy_train = []\n",
    "best_accuracy_val = []\n",
    "last_accuracy_val = []\n",
    "\n",
    "for i in range(tanh.shape[0]):\n",
    "  best_accuracy_train.append(np.max(tanh[i]))\n",
    "  last_accuracy_train.append(tanh[i,-1])\n",
    "  best_accuracy_val.append(np.max(tanhv[i]))\n",
    "  last_accuracy_val.append(tanhv[i,-1])\n",
    "\n",
    "best_accuracy_train = np.array(best_accuracy_train)\n",
    "last_accuracy_train = np.array(last_accuracy_train)\n",
    "best_accuracy_val = np.array(best_accuracy_val)\n",
    "last_accuracy_val = np.array(last_accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(115, 15))\n",
    "plt.subplot(1,2,1) \n",
    "plt.plot(tanh_comb, best_accuracy_train, 'r', label='train acc')\n",
    "plt.plot(tanh_comb, last_accuracy_train, 'o', label='last t acc')\n",
    "plt.plot(tanh_comb, best_accuracy_val, 'b', label='val acc')\n",
    "plt.plot(tanh_comb, last_accuracy_val, '*', label='last v acc')\n",
    "plt.title('TANH ACTIVATION')\n",
    "plt.xlabel('combination')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softplus_comb = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary:\n",
    "        softplus_comb.append(opt + ' ' + loss)\n",
    "\n",
    "best_accuracy_train = []\n",
    "last_accuracy_train = []\n",
    "best_accuracy_val = []\n",
    "last_accuracy_val = []\n",
    "\n",
    "for i in range(softplus.shape[0]):\n",
    "  best_accuracy_train.append(np.max(softplus[i]))\n",
    "  last_accuracy_train.append(softplus[i,-1])\n",
    "  best_accuracy_val.append(np.max(softplusv[i]))\n",
    "  last_accuracy_val.append(softplusv[i,-1])\n",
    "\n",
    "best_accuracy_train = np.array(best_accuracy_train)\n",
    "last_accuracy_train = np.array(last_accuracy_train)\n",
    "best_accuracy_val = np.array(best_accuracy_val)\n",
    "last_accuracy_val = np.array(last_accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(115, 15))\n",
    "plt.subplot(1,2,1) \n",
    "plt.plot(softplus_comb, best_accuracy_train, 'r', label='train acc')\n",
    "plt.plot(softplus_comb, last_accuracy_train, 'o', label='last t acc')\n",
    "plt.plot(softplus_comb, best_accuracy_val, 'b', label='val acc')\n",
    "plt.plot(softplus_comb, last_accuracy_val, '*', label='last v acc')\n",
    "plt.title('SOFTPLUS ACTIVATION')\n",
    "plt.xlabel('combination')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softsign_comb = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary:\n",
    "        softsign_comb.append(opt + ' ' + loss)\n",
    "\n",
    "best_accuracy_train = []\n",
    "last_accuracy_train = []\n",
    "best_accuracy_val = []\n",
    "last_accuracy_val = []\n",
    "\n",
    "for i in range(softsign.shape[0]):\n",
    "  best_accuracy_train.append(np.max(softsign[i]))\n",
    "  last_accuracy_train.append(softsign[i,-1])\n",
    "  best_accuracy_val.append(np.max(softsignv[i]))\n",
    "  last_accuracy_val.append(softsignv[i,-1])\n",
    "\n",
    "best_accuracy_train = np.array(best_accuracy_train)\n",
    "last_accuracy_train = np.array(last_accuracy_train)\n",
    "best_accuracy_val = np.array(best_accuracy_val)\n",
    "last_accuracy_val = np.array(last_accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(115, 15))\n",
    "plt.subplot(1,2,1) \n",
    "plt.plot(sigmoid_comb, best_accuracy_train, 'r', label='train acc')\n",
    "plt.plot(sigmoid_comb, last_accuracy_train, 'o', label='last t acc')\n",
    "plt.plot(sigmoid_comb, best_accuracy_val, 'b', label='val acc')\n",
    "plt.plot(sigmoid_comb, last_accuracy_val, '*', label='last v acc')\n",
    "plt.title('SOFTSIGN ACTIVATION')\n",
    "plt.xlabel('combination')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selu_comb = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary:\n",
    "        selu_comb.append(opt + ' ' + loss)\n",
    "\n",
    "best_accuracy_train = []\n",
    "last_accuracy_train = []\n",
    "best_accuracy_val = []\n",
    "last_accuracy_val = []\n",
    "\n",
    "for i in range(selu.shape[0]):\n",
    "  best_accuracy_train.append(np.max(selu[i]))\n",
    "  last_accuracy_train.append(selu[i,-1])\n",
    "  best_accuracy_val.append(np.max(seluv[i]))\n",
    "  last_accuracy_val.append(seluv[i,-1])\n",
    "\n",
    "best_accuracy_train = np.array(best_accuracy_train)\n",
    "last_accuracy_train = np.array(last_accuracy_train)\n",
    "best_accuracy_val = np.array(best_accuracy_val)\n",
    "last_accuracy_val = np.array(last_accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(115, 15))\n",
    "plt.subplot(1,2,1) \n",
    "plt.plot(selu_comb, best_accuracy_train, 'r', label='train acc')\n",
    "plt.plot(selu_comb, last_accuracy_train, 'o', label='last t acc')\n",
    "plt.plot(selu_comb, best_accuracy_val, 'b', label='val acc')\n",
    "plt.plot(selu_comb, last_accuracy_val, '*', label='last v acc')\n",
    "plt.title('SELU ACTIVATION')\n",
    "plt.xlabel('combination')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elu_comb = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary:\n",
    "        elu_comb.append(opt + ' ' + loss)\n",
    "\n",
    "best_accuracy_train = []\n",
    "last_accuracy_train = []\n",
    "best_accuracy_val = []\n",
    "last_accuracy_val = []\n",
    "\n",
    "for i in range(elu.shape[0]):\n",
    "  best_accuracy_train.append(np.max(elu[i]))\n",
    "  last_accuracy_train.append(elu[i,-1])\n",
    "  best_accuracy_val.append(np.max(eluv[i]))\n",
    "  last_accuracy_val.append(eluv[i,-1])\n",
    "\n",
    "best_accuracy_train = np.array(best_accuracy_train)\n",
    "last_accuracy_train = np.array(last_accuracy_train)\n",
    "best_accuracy_val = np.array(best_accuracy_val)\n",
    "last_accuracy_val = np.array(last_accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(115, 15))\n",
    "plt.subplot(1,2,1) \n",
    "plt.plot(elu_comb, best_accuracy_train, 'r', label='train acc')\n",
    "plt.plot(elu_comb, last_accuracy_train, 'o', label='last t acc')\n",
    "plt.plot(elu_comb, best_accuracy_val, 'b', label='val acc')\n",
    "plt.plot(elu_comb, last_accuracy_val, '*', label='last v acc')\n",
    "plt.title('ELU ACTIVATION')\n",
    "plt.xlabel('combination')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_comb = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary:\n",
    "        exp_comb.append(opt + ' ' + loss)\n",
    "\n",
    "best_accuracy_train = []\n",
    "last_accuracy_train = []\n",
    "best_accuracy_val = []\n",
    "last_accuracy_val = []\n",
    "\n",
    "for i in range(exp.shape[0]):\n",
    "  best_accuracy_train.append(np.max(exp[i]))\n",
    "  last_accuracy_train.append(exp[i,-1])\n",
    "  best_accuracy_val.append(np.max(expv[i]))\n",
    "  last_accuracy_val.append(expv[i,-1])\n",
    "\n",
    "best_accuracy_train = np.array(best_accuracy_train)\n",
    "last_accuracy_train = np.array(last_accuracy_train)\n",
    "best_accuracy_val = np.array(best_accuracy_val)\n",
    "last_accuracy_val = np.array(last_accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(115, 15))\n",
    "plt.subplot(1,2,1) \n",
    "plt.plot(exp_comb, best_accuracy_train, 'r', label='train acc')\n",
    "plt.plot(exp_comb, last_accuracy_train, 'o', label='last t acc')\n",
    "plt.plot(exp_comb, best_accuracy_val, 'b', label='val acc')\n",
    "plt.plot(exp_comb, last_accuracy_val, '*', label='last v acc')\n",
    "plt.title('EXPonential ACTIVATION')\n",
    "plt.xlabel('combination')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_comb = []\n",
    "\n",
    "for opt in optimizers:\n",
    "    for loss in binary:\n",
    "        relu_comb.append(opt + ' ' + loss)\n",
    "\n",
    "best_accuracy_train = []\n",
    "last_accuracy_train = []\n",
    "best_accuracy_val = []\n",
    "last_accuracy_val = []\n",
    "\n",
    "for i in range(relu.shape[0]):\n",
    "  best_accuracy_train.append(np.max(relu[i]))\n",
    "  last_accuracy_train.append(relu[i,-1])\n",
    "  best_accuracy_val.append(np.max(reluv[i]))\n",
    "  last_accuracy_val.append(reluv[i,-1])\n",
    "\n",
    "best_accuracy_train = np.array(best_accuracy_train)\n",
    "last_accuracy_train = np.array(last_accuracy_train)\n",
    "best_accuracy_val = np.array(best_accuracy_val)\n",
    "last_accuracy_val = np.array(last_accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(115, 15))\n",
    "plt.subplot(1,2,1) \n",
    "plt.plot(relu_comb, best_accuracy_train, 'r', label='train acc')\n",
    "plt.plot(relu_comb, last_accuracy_train, 'o', label='last t acc')\n",
    "plt.plot(relu_comb, best_accuracy_val, 'b', label='val acc')\n",
    "plt.plot(relu_comb, last_accuracy_val, '*', label='last v acc')\n",
    "plt.title('RELU ACTIVATION')\n",
    "plt.xlabel('combination')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
